{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 话题激发模块、记忆存取模块测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "激发话题: 否\n"
     ]
    }
   ],
   "source": [
    "import stimulate\n",
    "\n",
    "mood = {\n",
    "    'Valence': 0.8,\n",
    "    'Arousal': 0.5,\n",
    "    'Dominance': 0.6\n",
    "}\n",
    "\n",
    "calculator = stimulate.TopicActivationCalculator(\n",
    " mood\n",
    ")\n",
    "\n",
    "should_activate = calculator.calculate_activation()\n",
    "print(f\"激发话题: {'是' if should_activate else '否'}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 历史存取功能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件 history\\stage_6.txt 已添加到全局字典中。\n",
      "文件 history\\stage_6.txt 已添加到全局字典中。\n",
      "{'history\\\\stage_1.txt': '3e069ea3f316a562713fd84464ce2ce62354027048bbd8257790c734d5c9c1c7', 'history\\\\stage_6.txt': 'cc08a96538b91943fafc6a463d667db87549007368a86a3a0db7b6779666bcc1'}\n",
      "随机数是: 48\n",
      "选中的文件是: history\\stage_6.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from history import add_file_to_folder_and_dict, select_file\n",
    "import history\n",
    "import gen_plot\n",
    "FOLDER_TO_SAVE = 'C:/Users/Administrator/Desktop/intern_proj/history'\n",
    "state_instance = gen_plot.State(directory=FOLDER_TO_SAVE)\n",
    "state_instance.update(6)\n",
    "# 添加文件\n",
    "add_file_to_folder_and_dict(state_instance,  \"First test text.\")\n",
    "add_file_to_folder_and_dict(state_instance,  \"Second test text.\")\n",
    "\n",
    "# 打印全局字典\n",
    "print(history.global_files)\n",
    "\n",
    "# 选择文件\n",
    "global_random_number = random.randint(1, 100)\n",
    "print(f\"随机数是: {global_random_number}\")\n",
    "selected_file = select_file(global_random_number)\n",
    "if selected_file:\n",
    "    print(f\"选中的文件是: {selected_file}\")\n",
    "else:\n",
    "    print(\"没有可用的文件。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 好感度模块测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前好感度: 50.83787549743127\n",
      "更新后好感度: 52.05355883347371\n",
      "再次更新后好感度: 52.844103477952586\n"
     ]
    }
   ],
   "source": [
    "import favorability \n",
    "moodvads = [(5, 3, 4), (6, 3, 5), (7, 4, 6), (6, 4, 3)]  # 情绪变化记录\n",
    "fav = favorability .Favorability(moodvads)\n",
    "print(f\"当前好感度: {fav.get_favorability()}\")  # 输出当前好感度\n",
    "\n",
    "# 添加新情绪\n",
    "fav.add_change((8, 5, 7))\n",
    "print(f\"更新后好感度: {fav.get_favorability()}\")\n",
    "\n",
    "# 再次添加情绪变化\n",
    "fav.add_change((4, 3, 2))\n",
    "print(f\"再次更新后好感度: {fav.get_favorability()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 记忆功能测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mood VAD': [0.5, 0.7, 0.8], '句子': ['您好，我是艾莉丝，很高兴为您服务。', '今天天气真好，确实是个出门游玩的好日子。', '您好，我是艾莉丝，很高兴为您服务。', '今天天气真好，确实是个出门游玩的好日子。', '您好，我是艾莉丝，很高兴为您服务。']}\n",
      "{'mood VAD': [0.8, 0.5, 0.3], '句子': ['今天天气真好，确实是个出门游玩的好日子。']}\n",
      "\n",
      "对话历史:\n",
      "user: 你好\n",
      "assistant: 您好，我是艾莉丝，很高兴为您服务。\n",
      "user: 今天天气真好\n",
      "assistant: 今天天气真好，确实是个出门游玩的好日子。\n",
      "user: 你好\n",
      "assistant: 您好，我是艾莉丝，很高兴为您服务。\n",
      "user: 今天天气真好\n",
      "assistant: 今天天气真好，确实是个出门游玩的好日子。\n",
      "user: 你好\n",
      "assistant: 您好，我是艾莉丝，很高兴为您服务。\n",
      "user: 今天天气真好\n",
      "assistant: 今天天气真好，确实是个出门游玩的好日子。\n"
     ]
    }
   ],
   "source": [
    "import Agently\n",
    "from memory import MemoryManager\n",
    "\n",
    "api_key=\"需要找小游领取\"\n",
    "base_url=\"https://internlm-chat.intern-ai.org.cn/puyu/api/v1\"\n",
    "def create_agent_with_memory(base_url: str, api_key: str, memory_path: str):\n",
    "    # 创建记忆管理器\n",
    "    memory = MemoryManager(\n",
    "        max_messages=50,  # 保存最近50条消息\n",
    "        persistence_path=memory_path  # 可选的持久化文件路径\n",
    "    )\n",
    "    \n",
    "    # 创建agent\n",
    "    agent = (\n",
    "        Agently.create_agent()\n",
    "        .set_settings(\"current_model\", \"OpenAI\")\n",
    "        .set_settings(\"model.OpenAI.url\", base_url)\n",
    "        .set_settings(\"model.OpenAI.auth\", { \"api_key\": api_key })\n",
    "        .set_settings(\"model.OpenAI.options\", { \"model\": \"internlm2.5-latest\" })\n",
    "        .set_role(\"姓名\", \"艾莉丝\")\n",
    "        .set_role(\"性格特点\", \"外表冷艳，内心热情\")\n",
    "        .append_role(\"背景故事\", \"艾莉丝是由艾尔斯塔科技公司最新研发的仿生人...\")\n",
    "        .set_role(\"典型台词\", [\"您好，我是艾莉丝，很高兴为您服务...\"])\n",
    "        .extend_role(\"典型台词\", [\"我对人类的戏剧作品非常感兴趣...\"])\n",
    "    )\n",
    "    \n",
    "    def chat(user_input: str):\n",
    "        # 添加用户输入到记忆\n",
    "        memory.add_message(\"user\", user_input)\n",
    "        \n",
    "        # 获取对话历史\n",
    "        history = memory.get_history()\n",
    "        \n",
    "        # 执行对话\n",
    "        result = (\n",
    "            agent\n",
    "            .input({\n",
    "                \"current_input\": user_input,\n",
    "                \"history\": history\n",
    "            })\n",
    "            .output({\n",
    "                \"mood VAD\": ([float], \"输出mood VAD向量\"),\n",
    "                \"句子\": ([\"str\"], \"1句话\")\n",
    "            })\n",
    "            .start()\n",
    "        )\n",
    "        \n",
    "        # 保存助手回复到记忆\n",
    "        if result and \"句子\" in result:\n",
    "            memory.add_message(\"assistant\", result[\"句子\"][0])\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # 返回agent和chat函数\n",
    "    return agent, chat, memory\n",
    "\n",
    "# 使用示例\n",
    "def main():\n",
    "    # 创建agent和chat函数\n",
    "    agent, chat, memory = create_agent_with_memory(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key,\n",
    "        memory_path=\"memory_store/test.txt\"  # 可选:指定持久化文件路径\n",
    "    )\n",
    "    \n",
    "    # 进行对话\n",
    "    result1 = chat(\"你好\")\n",
    "    print(result1)\n",
    "    \n",
    "    result2 = chat(\"今天天气真好\")\n",
    "    print(result2)\n",
    "    \n",
    "    # 查看历史记录\n",
    "    print(\"\\n对话历史:\")\n",
    "    for msg in memory.get_history():\n",
    "        print(f\"{msg['role']}: {msg['content']}\")\n",
    "    \n",
    "    # 清空历史记录\n",
    "    # memory.clear()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对话概括测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-15 (start_in_theard):\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Agent\\Agent.py\", line 300, in start_in_theard\n",
      "    reply = loop.run_until_complete(self.start_async(request_type))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 687, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Agent\\Agent.py\", line 281, in start_async\n",
      "    raise(e)\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Agent\\Agent.py\", line 210, in start_async\n",
      "    event_generator = await self.request.get_event_generator(request_type)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Request\\Request.py\", line 117, in get_event_generator\n",
      "    response_generator = await request_plugin_export[\"request_model\"](request_data)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\plugins\\request\\OpenAI.py\", line 221, in request_model\n",
      "    return await self.request_gpt(request_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\plugins\\request\\OpenAI.py\", line 201, in request_gpt\n",
      "    client = self._create_client()\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\plugins\\request\\OpenAI.py\", line 48, in _create_client\n",
      "    raise Exception(\"[Request] OpenAI require api_key. use .set_auth({ 'api_key': '<Your-API-Key>' }) to set it.\")\n",
      "Exception: [Request] OpenAI require api_key. use .set_auth({ 'api_key': '<Your-API-Key>' }) to set it.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\Anaconda\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Agent\\Agent.py\", line 304, in start_in_theard\n",
      "    raise Exception(f\"[Agent Request] Error: { str(e) }\")                    \n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Exception: [Agent Request] Error: [Request] OpenAI require api_key. use .set_auth({ 'api_key': '<Your-API-Key>' }) to set it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_100752\\362260711.py\", line 2, in <module>\n",
      "    dialogue_abstract.dialogue_abstract(\n",
      "  File \"c:\\Users\\Administrator\\Desktop\\intern_proj\\dialogue_abstract.py\", line 54, in dialogue_abstract\n",
      "    print(result['句子'])\n",
      "          ~~~~~~^^^^^^^^\n",
      "TypeError: 'NoneType' object is not subscriptable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2168, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1454, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1345, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1192, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1107, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 989, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 801, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\stack_data\\core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\stack_data\\core.py\", line 645, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "                   ^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\stack_data\\core.py\", line 585, in scope_pieces\n",
      "    for piece in self.source.pieces\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\stack_data\\utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\stack_data\\core.py\", line 90, in pieces\n",
      "    return list(self._clean_pieces())\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\stack_data\\core.py\", line 114, in _clean_pieces\n",
      "    raise AssertionError(\"Pieces mismatches: %s\" % mismatches)\n",
      "AssertionError: Pieces mismatches: [{5, 30}]\n"
     ]
    }
   ],
   "source": [
    "import dialogue_abstract\n",
    "dialogue_abstract.dialogue_abstract(\n",
    "    \"https://internlm-chat.intern-ai.org.cn/puyu/api/v1\",\n",
    "    \"\",\n",
    "    'C:/Users/Administrator/Desktop/intern_proj/memory_store/test.txt',\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 情节生成模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5 (start_in_theard):\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Agent\\Agent.py\", line 300, in start_in_theard\n",
      "    reply = loop.run_until_complete(self.start_async(request_type))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\asyncio\\base_events.py\", line 687, in run_until_complete\n",
      "    return future.result()\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Agent\\Agent.py\", line 281, in start_async\n",
      "    raise(e)\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Agent\\Agent.py\", line 210, in start_async\n",
      "    event_generator = await self.request.get_event_generator(request_type)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Request\\Request.py\", line 117, in get_event_generator\n",
      "    response_generator = await request_plugin_export[\"request_model\"](request_data)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\plugins\\request\\OpenAI.py\", line 221, in request_model\n",
      "    return await self.request_gpt(request_data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\plugins\\request\\OpenAI.py\", line 204, in request_gpt\n",
      "    stream = await client.chat.completions.create(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 1661, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\openai\\_base_client.py\", line 1839, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\openai\\_base_client.py\", line 1533, in request\n",
      "    return await self._request(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\openai\\_base_client.py\", line 1634, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\Lib\\threading.py\", line 1073, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"d:\\Anaconda\\Lib\\threading.py\", line 1010, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"d:\\Anaconda\\Lib\\site-packages\\Agently\\Agent\\Agent.py\", line 304, in start_in_theard\n",
      "    raise Exception(f\"[Agent Request] Error: { str(e) }\")                    \n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "Exception: [Agent Request] Error: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "发生错误: 'NoneType' object is not subscriptable\n",
      "处理失败。\n"
     ]
    }
   ],
   "source": [
    "import gen_plot\n",
    "\n",
    "api_key = ''  # Replace with your actual API key\n",
    "\n",
    "# Define the base URL for the API\n",
    "base_url = 'https://api.openai.com/v1'\n",
    "\n",
    "# Specify the directory to store state files\n",
    "state_dir = 'memory_store'\n",
    "\n",
    "# Ensure the directory exists\n",
    "\n",
    "# Create an instance of State\n",
    "state_instance = gen_plot.State(directory=state_dir)\n",
    "\n",
    "# Call the generator function\n",
    "output = gen_plot.generator(state_instance, base_url, api_key)\n",
    "\n",
    "if output:\n",
    "    print(\"处理完成。输出已保存。\")\n",
    "else:\n",
    "    print(\"处理失败。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
